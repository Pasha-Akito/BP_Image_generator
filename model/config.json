{"vocab_size": 69, "embedding_dimensions": 512, "total_attention_heads": 16, "total_encoder_layers": 8, "max_token_size": 64, "latent_dim": 128}